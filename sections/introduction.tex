Quantum computing (QC) has the potential to revolutionize numerous scientific and industrial domains by solving certain otherwise intractable problems \cite{alexeev2021quantum}. As quantum hardware progresses from noisy intermediate-scale quantum (NISQ) devices toward fault-tolerant quantum computing (FTQC), researchers face numerous challenges in hardware design, error correction, and algorithm development.

The complexity and non-linear nature of quantum mechanical systems make them particularly well-suited for artificial intelligence approaches \cite{dunjko2023artificial}. AI techniques offer powerful tools for recognizing patterns in high-dimensional spaces and finding solutions to complex optimization problems that arise throughout the quantum computing stack.

This review examines applications of state-of-the-art AI techniques that are advancing quantum computing research and development. We focus solely on how AI is advancing quantum computing (AI for quantum) rather than how quantum computers might eventually enhance AI (quantum for AI). The content is organized according to the sequence of tasks undertaken in designing and operating quantum computers, from hardware development through preprocessing, control, error correction, and postprocessing.

\subsection{A Brief Survey of AI Methods}
Machine learning (ML) encompasses various approaches to enabling computers to learn from data without explicit programming \cite{janiesch2021machine}. Within ML, we can distinguish several paradigms relevant to quantum computing:

\begin{itemize}
    \item \textbf{Supervised learning}: Models learn from labeled training data to make predictions on new inputs.
    \item \textbf{Unsupervised learning}: Models identify patterns in unlabeled data, often through clustering or dimensionality reduction.
    \item \textbf{Reinforcement learning (RL)}: Agents learn optimal behaviors through interaction with an environment, receiving rewards or penalties \cite{arulkumaran2017deep, shakya2023reinforcement}.
    \item \textbf{Deep learning}: Neural networks with multiple layers extract hierarchical features from data \cite{lecun2015deep}.
    \item \textbf{Generative models}: Models that can generate new content similar to their training data \cite{bernardo2007generative}.
    \item \textbf{Transformer models}: Attention-based architectures particularly successful in natural language processing and increasingly applied to other domains \cite{vaswani2017attention}.
    \item \textbf{Diffusion models}: Generative models that learn to reverse a gradual noising process \cite{ho2020denoising}.
\end{itemize}

These techniques are being applied throughout quantum computing research, with varying degrees of specialization to quantum-specific challenges. 